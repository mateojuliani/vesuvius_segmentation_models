{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "516e002a-4772-4213-b297-620854973505",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f4c31-7ea8-4631-891d-627474cf28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "import cv2\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import argparse\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "\n",
    "import datetime\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25ed2b-98ac-4601-ac97-be5129a5e083",
   "metadata": {},
   "source": [
    "# Helper Functions & Configs File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb9e38-5d42-4d01-8d2e-d4b2bd94276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cpu_stats():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memory_use = py.memory_info()[0] / 2. ** 30\n",
    "    return 'memory GB:' + str(np.round(memory_use, 2))\n",
    "\n",
    "#| export\n",
    "def detect_env():\n",
    "    \"\"\"A helper function that detects where you are running code\"\"\"\n",
    "    if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", False):\n",
    "        run_env = \"kaggle\"\n",
    "    elif os.path.isdir(\"/content\"):\n",
    "        run_env = \"colab\"\n",
    "    elif os.path.isdir(\"../nbs\") or os.path.isdir(\"../../nbs\"):\n",
    "        run_env = \"local_nb\"\n",
    "    else:\n",
    "        run_env = \"script\"\n",
    "\n",
    "    return run_env        \n",
    "\n",
    "# | export\n",
    "def get_paths(run_env = \"local_nb\"):\n",
    "    \"\"\"Returns data, models, and log folder paths based on your where you are running the code\"\"\"\n",
    "    if run_env == \"kaggle\":\n",
    "        path_main = path_data = Path(f\"/kaggle/input/vesuvius-challenge-ink-detection\")\n",
    "        path_working = Path(\"/kaggle/working/outputs/\")\n",
    "\n",
    "    elif run_env == \"colab\":\n",
    "        path_main = path_working = path_data = Path(\"./\")\n",
    "\n",
    "    elif run_env == \"local_nb\":\n",
    "        path_main = path_working = Path(\"..\")\n",
    "        path_data = path_main / \"data\"\n",
    "\n",
    "    elif run_env == \"script\":\n",
    "        path_main = path_working = Path(\".\")\n",
    "        path_data = path_main / \"data\"\n",
    "        \n",
    "    path_models = path_working / \"models\"\n",
    "    path_logs = path_working / \"logs\"\n",
    "\n",
    "    try:\n",
    "        path_models.mkdir(parents=True, exist_ok=True)\n",
    "        path_logs.mkdir(parents=True, exist_ok=True)\n",
    "    except:\n",
    "        print(\"Unable to create models and logs folders\")\n",
    "\n",
    "    path_train = path_data / \"train\"\n",
    "    path_test = path_data / \"test/\"\n",
    "\n",
    "    return path_train, path_test, path_models, path_logs, path_working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921acc74-0d0f-40e1-8bae-322f7f276289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CFG:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 4321\n",
    "        self.subset = 1.0\n",
    "        self.n_fold = 5\n",
    "        self.val_fold = 0\n",
    "        self.img_size = 224\n",
    "        self.bs = 8\n",
    "        self.frag_min = 31 # 15\n",
    "        self.frag_len = 4\n",
    "        self.merge_img = \"1d\"  # \"1d\", \"3d\", \"none\"\n",
    "        self.norm_img = False\n",
    "        self.frag_sel = [\"1\", \"2\", \"3\"]\n",
    "        self.fold_split = \"stratify\"  # \"stratify\", \"fragment\"\n",
    "        self.augment = \"baseline\" #\"bright_dropout_blur\"\n",
    "        self.preproc = \"basic\"\n",
    "        self.postproc = \"none\"\n",
    "        self.train_folds = \"train_folds.csv\"\n",
    "        self.checkpoint = 'tu-eca_nfnet_l1'\n",
    "        self.loss = \"ce_weighted\"\n",
    "        self.metric = \"fbeta\"\n",
    "        self.use_fp16 = True\n",
    "        self.n_epochs = 15  #we're doing early stopping\n",
    "        self.lr = 5e-5  # number or 'find' to use lr_find\n",
    "        self.framework = \"fastai\"\n",
    "        self.run_id = \"null\"\n",
    "        self.grid_id = -1\n",
    "        self.save_oof = False\n",
    "        \n",
    "        self.tile_size = 224\n",
    "        self.stride = self.tile_size // 2\n",
    "        self.valid_batch_size = self.bs * 2 #This needs to be added\n",
    "        self.use_amp = True #need to add this to cfg\n",
    "        self.scheduler = 'GradualWarmupSchedulerV2'\n",
    "        self.warmup_factor = 10 #Need to add this \n",
    "        self.smp_lr = 1e-4 / self.warmup_factor #Need to add this\n",
    "        self.max_grad_norm = 1000 #To be added\n",
    "        self.num_workers = 4 #needs to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab86204-7f52-49e7-9ef0-8ed7a651f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#from the util package, but putting here to make it easier\n",
    "def get_train_aug_resize(img_size, in_chans): return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "def get_valid_aug_resize(img_size, in_chans): return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "], p=1.)\n",
    "\n",
    "\n",
    "def get_train_aug_brightness(img_size, in_chans): return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.RandomBrightnessContrast(p = 0.5),\n",
    "    albumentations.HueSaturationValue(p = 0.5),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "def get_train_aug_bright_dropout_geom_blur(img_size, in_chans): return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.RandomBrightnessContrast(p = 0.5),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.Blur(p = 0.5),\n",
    "    albumentations.CoarseDropout(p = 0.5),\n",
    "    albumentations.ShiftScaleRotate(p=0.5, rotate_limit=15),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "def get_train_aug_public_baseline(img_size, in_chans):  return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.RandomBrightnessContrast(p=0.75),\n",
    "    albumentations.ShiftScaleRotate(p=0.75),\n",
    "    albumentations.OneOf([\n",
    "            albumentations.GaussNoise(var_limit=[10, 50]),\n",
    "            albumentations.GaussianBlur(),\n",
    "            albumentations.MotionBlur(),\n",
    "            ], p=0.4),\n",
    "    albumentations.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "    albumentations.CoarseDropout(max_holes=1, max_width=int(img_size * 0.3), max_height=int(img_size * 0.3), \n",
    "                    mask_fill_value=0, p=0.5),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "def get_train_transforms(cfg):\n",
    "    \n",
    "    # augmentations\n",
    "    #---------------------\n",
    "    if cfg.augment == \"basic\":\n",
    "        get_train_aug = get_train_aug_resize\n",
    "    elif cfg.augment == \"brightness\":\n",
    "        get_train_aug = get_train_aug_brightness\n",
    "#     elif cfg.augment == \"geometry\":\n",
    "#         get_train_aug = get_train_aug_geometry\n",
    "    elif cfg.augment == \"baseline\":\n",
    "        get_train_aug = get_train_aug_public_baseline\n",
    "    elif cfg.augment == \"bright_dropout_geom_blur\":\n",
    "        get_train_aug = get_train_aug_bright_dropout_geom_blur\n",
    "    else:\n",
    "        get_train_aug = get_train_aug_resize\n",
    "        \n",
    "        \n",
    "    return get_train_aug(cfg.img_size, cfg.frag_len)\n",
    "\n",
    "def get_valid_transforms(cfg):\n",
    "    get_valid_aug = get_valid_aug_resize\n",
    "    return get_valid_aug(cfg.img_size, cfg.frag_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331af26-ff85-407f-b160-6be32908ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "def init_logger(log_file):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "def set_seed(seed=None, cudnn_deterministic=True):\n",
    "    if seed is None:\n",
    "        seed = 42\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = cudnn_deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def make_dirs(cfg):\n",
    "    \n",
    "    for dir in [CFG.model_dir, CFG.figures_dir, CFG.submission_dir, CFG.log_dir]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "        \n",
    "def cfg_init(cfg, mode='train'):\n",
    "    set_seed(cfg.random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9076b3-8fa5-4eaf-92ab-df43d5572cd9",
   "metadata": {},
   "source": [
    "# Reading Image + Mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809d3d24-5d05-4b2d-87b0-92959d33b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def read_image_mask(CFG, fragment_id, path_train): ##Reads an individual mask framgment\n",
    "\n",
    "    images = []\n",
    "\n",
    "    start = CFG.frag_min\n",
    "    end = CFG.frag_min + CFG.frag_len\n",
    "    idxs = range(start, end)\n",
    "\n",
    "    for i in tqdm(idxs):\n",
    "\n",
    "        image_path = str(path_train / f\"{fragment_id}/surface_volume/{i:02}.tif\")\n",
    "        image = cv2.imread(image_path, 0)\n",
    "\n",
    "        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
    "        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n",
    "\n",
    "        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "        images.append(image)\n",
    "    images = np.stack(images, axis=2)\n",
    "\n",
    "    mask_path = str(path_train / f\"{fragment_id}/inklabels.png\")\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "    mask = mask.astype('float32')\n",
    "    mask /= 255.0\n",
    "    \n",
    "    label_path = str(path_train / f\"{fragment_id}/mask.png\")\n",
    "    label = cv2.imread(label_path, 0)\n",
    "    label = np.pad(label, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "    label = label.astype('float32')\n",
    "    label /= 255.0\n",
    "    \n",
    "    return images, mask, label.astype('int8')\n",
    "\n",
    "def read_all_fragments(CFG, path_train): #Gets training/val data \n",
    "    \n",
    "    full_images = []\n",
    "    full_masks = []\n",
    "    full_xyxys = []\n",
    "\n",
    "    for fragment_id in range(1, 4): \n",
    "        \n",
    "        images = []\n",
    "        masks = []\n",
    "        xyxys = []\n",
    "        \n",
    "        image, mask, label = read_image_mask(CFG, fragment_id, path_train)\n",
    "\n",
    "        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
    "        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n",
    "\n",
    "        for y1 in y1_list:\n",
    "            for x1 in x1_list:\n",
    "                y2 = y1 + CFG.tile_size\n",
    "                x2 = x1 + CFG.tile_size\n",
    "                # xyxys.append((x1, y1, x2, y2))\n",
    "                \n",
    "                if np.max(label[y1:y2, x1:x2]) == 1: #we have ink here\n",
    "                    images.append(image[y1:y2, x1:x2])\n",
    "                    masks.append(mask[y1:y2, x1:x2, None])\n",
    "                    xyxys.append([x1, y1, x2, y2])\n",
    "        \n",
    "        \n",
    "        full_images.append(images)\n",
    "        full_masks.append(masks)\n",
    "        full_xyxys.append(xyxys)\n",
    "        \n",
    "        del image, mask, label\n",
    "        gc.collect()\n",
    "\n",
    "    return full_images, full_masks, full_xyxys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c0992a-a6fd-4da1-b961-ceb5fe9ced39",
   "metadata": {},
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d2b36-62ee-4783-959c-54a741278fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_transforms(data, cfg): \n",
    "    if data == 'train':\n",
    "        aug = get_train_transforms(cfg)\n",
    "    elif data == 'valid':\n",
    "        aug = get_valid_transforms(cfg)\n",
    "\n",
    "    # print(aug)\n",
    "    return aug\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, cfg, labels=None, transform=None):\n",
    "        self.images = images\n",
    "        self.cfg = cfg\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.df)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(image=image, mask=label)\n",
    "            image = data['image']\n",
    "            label = data['mask']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc635f91-1e3f-46e3-a92f-4f13ebd8c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "  \n",
    "def create_dataloaders_new(CFG, full_images, full_masks, full_xyxys, valid_id):\n",
    "    valid_id_int = int(valid_id) - 1\n",
    "    \n",
    "    valid_images = full_images[valid_id_int]\n",
    "    valid_masks = full_masks[valid_id_int]\n",
    "    valid_xyxys  = full_xyxys[valid_id_int]\n",
    "    \n",
    "    if valid_id_int == 0:\n",
    "        train_images = full_images[1] + full_images[2]\n",
    "        train_masks = full_masks[1] + full_masks[2]\n",
    "    elif valid_id_int == 1:\n",
    "        train_images = full_images[0] + full_images[2]\n",
    "        train_masks = full_masks[0] + full_masks[2] \n",
    "    elif valid_id_int == 2:\n",
    "        train_images = full_images[0] + full_images[1]\n",
    "        train_masks = full_masks[0] + full_masks[1]  \n",
    "    \n",
    "    #train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset(valid_id)\n",
    "    #valid_xyxys = np.stack(valid_xyxys)\n",
    "    \n",
    "    train_dataset = CustomDataset(\n",
    "    train_images, CFG, labels=train_masks, transform=get_transforms(data='train', cfg=CFG))\n",
    "    valid_dataset = CustomDataset(\n",
    "        valid_images, CFG, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.bs,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n",
    "                              )\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.valid_batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    #print(len(train_loader))\n",
    "    #print(len(valid_loader))\n",
    "    return train_loader, valid_loader, valid_xyxys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe0f09-949d-48c1-92e2-2ba005270968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def valid_mask_gt_func(fragment_id, path_train, CFG):\n",
    "    valid_mask_path = str(path_train / f\"{fragment_id}/inklabels.png\")\n",
    "    valid_mask_gt = cv2.imread(valid_mask_path, 0)\n",
    "    valid_mask_gt = valid_mask_gt / 255\n",
    "    pad0 = (CFG.tile_size - valid_mask_gt.shape[0] % CFG.tile_size)\n",
    "    pad1 = (CFG.tile_size - valid_mask_gt.shape[1] % CFG.tile_size)\n",
    "    valid_mask_gt = np.pad(valid_mask_gt, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "    return valid_mask_gt.astype('float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de214e7-dce3-4843-896c-8d18c88946da",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b709c4-6689-45fe-ad13-ae0f972368be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, weight=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.encoder = smp.Unet(\n",
    "            encoder_name=cfg.checkpoint, \n",
    "            encoder_weights=weight,\n",
    "            in_channels=cfg.frag_len,\n",
    "            classes=1, #hard coding for now \n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.encoder(image)\n",
    "        # output = output.squeeze(-1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def build_model(cfg, weight=\"imagenet\"):\n",
    "    print('model_name', \"Unet\") #used to be cfg.model_name\n",
    "    print('checkpoint', cfg.checkpoint)\n",
    "\n",
    "    model = CustomModel(cfg, weight)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324c364-15f0-49c5-a386-2129c9aa0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def initalize_model(device, CFG):\n",
    "    model = build_model(CFG)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG.smp_lr)\n",
    "    scheduler = get_scheduler(CFG, optimizer)\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de89ca3-7832-4e7e-86ce-9aec0bae6609",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a14e64-40af-451f-b8ec-0a701e62f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    BCELoss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "    return BCELoss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03723b7-bd31-469a-b6f6-532fda4f2a38",
   "metadata": {},
   "source": [
    "# Train / Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567d26d-e59f-4b37-a769-c482b64ad522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_fn(train_loader, model, criterion, optimizer, device, CFG):\n",
    "    model.train()\n",
    "\n",
    "    scaler = GradScaler(enabled=CFG.use_amp)\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with autocast(CFG.use_amp):\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt, CFG):\n",
    "    mask_pred = np.zeros(valid_mask_gt.shape)\n",
    "    mask_count = np.zeros(valid_mask_gt.shape)\n",
    "\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # make whole mask\n",
    "        y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n",
    "        start_idx = step*CFG.valid_batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        for i, (x1, y1, x2, y2) in enumerate(valid_xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n",
    "            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n",
    "\n",
    "    print(f'mask_count_min: {mask_count.min()}')\n",
    "    mask_pred /= mask_count\n",
    "    return losses.avg, mask_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa02e79-0cc6-4e2a-9fc9-849a9d02c247",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2efd6-a182-4f79-a1d1-91ed42d2a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n",
    "    \"\"\"\n",
    "    y_true_count = targets.sum()\n",
    "    ctp = preds[targets==1].sum()\n",
    "    cfp = preds[targets==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "\n",
    "    c_precision = ctp / (ctp + cfp + smooth)\n",
    "    c_recall = ctp / (y_true_count + smooth)\n",
    "    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def calc_fbeta(mask, mask_pred):\n",
    "    mask = mask.astype(int).flatten()\n",
    "    mask_pred = mask_pred.flatten()\n",
    "\n",
    "    best_th = 0\n",
    "    best_dice = 0\n",
    "    dice = fbeta_numpy(mask, (mask_pred >= 0.5).astype(int), beta=0.5)\n",
    "    \n",
    "    best_dice = dice\n",
    "    best_th = 0.5 #assumed this is 0.5 vs iterating over different thresholds\n",
    "    \n",
    "# Commented this out to save memory \n",
    "#     for th in np.array(range(10, 50+1, 5)) / 100:\n",
    "        \n",
    "#         # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n",
    "#         dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n",
    "#         print(f'th: {th}, fbeta: {dice}')\n",
    "\n",
    "#         if dice > best_dice:\n",
    "#             best_dice = dice\n",
    "#             best_th = th\n",
    "    \n",
    "#     Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n",
    "    \n",
    "    return best_dice, best_th\n",
    "\n",
    "\n",
    "def calc_cv(mask_gt, mask_pred):\n",
    "    best_dice, best_th = calc_fbeta(mask_gt, mask_pred)\n",
    "\n",
    "    return best_dice, best_th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7ee61-7c67-4225-993c-af055eb3ba85",
   "metadata": {},
   "source": [
    "# Driver Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967c511-82dd-48d8-9dee-b54a387cf1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def train_one_fold(CFG, full_images, full_masks, full_xyxys, fold, device, path_train, path_test, path_models, path_logs, path_working): #Inputs are config file, underlying data, and fold num \n",
    "    \n",
    "    \n",
    "    best_score = -1\n",
    "    # timing\n",
    "    start_all = time.time()\n",
    "    \n",
    "    best_epoch_num = 0\n",
    "\n",
    "#     run_id = CFG.run_id\n",
    "#     grid_id = CFG.grid_id\n",
    "\n",
    "    #full_images, full_masks, full_xyxys = read_all_fragments() #reads and puts all fragments in list\n",
    "    #Note the above code ^^^^ doesnt need to be re-initalized every fold.\n",
    "    ###Maybe we create it in pre-proc and just pass it thru\n",
    "\n",
    "    train_loader, valid_loader, valid_xyxys = create_dataloaders_new(CFG, full_images ,full_masks ,full_xyxys, fold) \n",
    "    valid_mask_gt = valid_mask_gt_func(fold, path_train, CFG) #Get validation mask\n",
    "    model, optimizer, scheduler = initalize_model(device, CFG)\n",
    "    \n",
    "    epoc_count_l = []\n",
    "    train_loss_l = []\n",
    "    val_loss_l = []\n",
    "    val_dice_l = []\n",
    "    best_dice_score_l = []\n",
    "    best_epoch_l = []\n",
    "    epoch_time_l = []\n",
    "    fold_list_l = []\n",
    "    \n",
    "    for epoch in range(CFG.n_epochs):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # train\n",
    "            avg_loss = train_fn(train_loader, model, criterion, optimizer, device, CFG)\n",
    "\n",
    "            print(f'post training {fold}: {cpu_stats()}')\n",
    "            # eval\n",
    "            avg_val_loss, mask_pred = valid_fn(\n",
    "                valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt, CFG)\n",
    "\n",
    "            scheduler_step(scheduler, avg_val_loss, epoch)\n",
    "\n",
    "            print(f'model end training cv: {cpu_stats()}')\n",
    "            best_dice, best_th = calc_cv(valid_mask_gt, mask_pred)\n",
    "\n",
    "            print(f'finished calc cv: {cpu_stats()}')\n",
    "            # score = avg_val_loss\n",
    "            score = best_dice\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "#             Logger.info(\n",
    "#                 f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "#             # Logger.info(f'Epoch {epoch+1} - avgScore: {avg_score:.4f}')\n",
    "#             Logger.info(\n",
    "#                 f'Epoch {epoch+1} - avgScore: {score:.4f}')\n",
    "\n",
    "\n",
    "            update_best = score > best_score\n",
    "\n",
    "            if update_best:\n",
    "                best_loss = avg_val_loss\n",
    "                best_score = score\n",
    "                best_epoch_num = epoch\n",
    "#                 Logger.info(\n",
    "#                     f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "#                 Logger.info(\n",
    "#                     f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "\n",
    "                print(f'saving model: {cpu_stats()}')\n",
    "                torch.save({'model': model.state_dict(),\n",
    "                            'preds': mask_pred},\n",
    "                            path_models / f'Unet_fold{fold}_best.pth')\n",
    "                print(f'model saved: {cpu_stats()}')\n",
    "\n",
    "            epoc_count_l.append(epoch)\n",
    "            train_loss_l.append(avg_loss)\n",
    "            val_loss_l.append(avg_val_loss)\n",
    "            val_dice_l.append(best_dice)\n",
    "            best_dice_score_l.append(best_score)\n",
    "            best_epoch_l.append(best_epoch_num)\n",
    "            epoch_time_l.append(elapsed)\n",
    "            fold_list_l.append(fold)\n",
    "            \n",
    "            \n",
    "    base_df = pd.DataFrame( #Create DF based on training data \n",
    "        list(zip(epoc_count_l ,train_loss_l ,val_loss_l ,val_dice_l ,best_dice_score_l ,best_epoch_l ,epoch_time_l, fold_list_l )),\n",
    "                      \n",
    "        columns = ['epoc_count','train_loss','val_loss','val_dice','best_dice','best_epoch','epoch_time', 'fold_number'])\n",
    "                     \n",
    "    cfg_df = pd.DataFrame([CFG.__dict__])\n",
    "\n",
    "    log_df = pd.concat([base_df, cfg_df], axis = 1)\n",
    "    log_df = log_df.fillna(method=\"ffill\")\n",
    "    \n",
    "    return log_df\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d442d-200e-45e8-b30d-92bcc02b3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_grid():\n",
    "    cfg = CFG()\n",
    "    cfg_init(cfg)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    path_train, path_test, path_models, path_logs, path_working = get_paths(detect_env())  #Gets our paths\n",
    "    \n",
    "    full_images, full_masks, full_xyxys = read_all_fragments(cfg, path_train) #Preprocessing, read in the fragments\n",
    "    \n",
    "    log_df_all = None\n",
    "    for fold in cfg.frag_sel: #valid_set is for the framgments we want to use in validation\n",
    "        log_df = train_one_fold(cfg, full_images, full_masks, full_xyxys, fold, device,\n",
    "                               path_train, path_test, path_models, path_logs, path_working) #Does one round of training\n",
    "        \n",
    "        if log_df_all is None:\n",
    "            log_df_all = log_df.copy()\n",
    "        else:\n",
    "            log_df_all = pd.concat([log_df_all, log_df])\n",
    "        \n",
    "    return log_df_all\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
