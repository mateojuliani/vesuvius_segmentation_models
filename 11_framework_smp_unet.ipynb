{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp framework_utils.smp_unet\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe7bef",
   "metadata": {},
   "source": [
    "\n",
    "# framework_utils.smp_unet\n",
    "\n",
    "> This module has all the smp unet specific code based on the 2.5d model. Dataloaders and Learners, together with their helper tools. Some of it might be generalizable to other frameworks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "import cv2\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import argparse\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "\n",
    "import datetime\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import psutil  \n",
    "\n",
    "#from kaggle_vesuvius import utils, config, preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Disable DecompressionBombWarning for fragment 2\n",
    "# Image.MAX_IMAGE_PIXELS = 150000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def detect_env():\n",
    "    \"\"\"A helper function that detects where you are running code\"\"\"\n",
    "    if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", False):\n",
    "        run_env = \"kaggle\"\n",
    "    elif os.path.isdir(\"/content\"):\n",
    "        run_env = \"colab\"\n",
    "    elif os.path.isdir(\"../nbs\") or os.path.isdir(\"../../nbs\"):\n",
    "        run_env = \"local_nb\"\n",
    "    else:\n",
    "        run_env = \"script\"\n",
    "\n",
    "    return run_env        \n",
    "\n",
    "# | export\n",
    "def get_paths(run_env = \"local_nb\"):\n",
    "    \"\"\"Returns data, models, and log folder paths based on your where you are running the code\"\"\"\n",
    "    if run_env == \"kaggle\":\n",
    "        path_main = path_data = Path(f\"/kaggle/input/vesuvius-challenge-ink-detection\")\n",
    "        path_working = Path(\"/kaggle/working/outputs/\")\n",
    "\n",
    "    elif run_env == \"colab\":\n",
    "        path_main = path_working = path_data = Path(\"./\")\n",
    "\n",
    "    elif run_env == \"local_nb\":\n",
    "        path_main = path_working = Path(\"..\")\n",
    "        path_data = path_main / \"data\"\n",
    "\n",
    "    elif run_env == \"script\":\n",
    "        path_main = path_working = Path(\".\")\n",
    "        path_data = path_main / \"data\"\n",
    "        \n",
    "    path_models = path_working / \"models\"\n",
    "    path_logs = path_working / \"logs\"\n",
    "\n",
    "    try:\n",
    "        path_models.mkdir(parents=True, exist_ok=True)\n",
    "        path_logs.mkdir(parents=True, exist_ok=True)\n",
    "    except:\n",
    "        print(\"Unable to create models and logs folders\")\n",
    "\n",
    "    path_train = path_data / \"train\"\n",
    "    path_test = path_data / \"test/\"\n",
    "\n",
    "    return path_train, path_test, path_models, path_logs, path_working\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b43a27",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242fcbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CFG:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 4321\n",
    "        self.subset = 1.0\n",
    "        self.n_fold = 5\n",
    "        self.val_fold = 0\n",
    "        self.img_size = 224\n",
    "        self.bs = 8\n",
    "        self.frag_min = 31 # 15\n",
    "        self.frag_len = 4\n",
    "        self.merge_img = \"1d\"  # \"1d\", \"3d\", \"none\"\n",
    "        self.norm_img = False\n",
    "        self.frag_sel = [\"1\", \"2\", \"3\"]\n",
    "        self.fold_split = \"stratify\"  # \"stratify\", \"fragment\"\n",
    "        self.augment = \"baseline\" #\"bright_dropout_blur\"\n",
    "        self.preproc = \"basic\"\n",
    "        self.postproc = \"none\"\n",
    "        self.train_folds = \"train_folds.csv\"\n",
    "        self.checkpoint = 'tu-eca_nfnet_l1'\n",
    "        self.loss = \"ce_weighted\"\n",
    "        self.metric = \"fbeta\"\n",
    "        self.use_fp16 = True\n",
    "        self.n_epochs = 15  #we're doing early stopping\n",
    "        self.lr = 5e-5  # number or 'find' to use lr_find\n",
    "        self.framework = \"fastai\"\n",
    "        self.run_id = \"null\"\n",
    "        self.grid_id = -1\n",
    "        self.save_oof = False\n",
    "        \n",
    "        self.tile_size = 224\n",
    "        self.stride = self.tile_size // 2\n",
    "        self.valid_batch_size = self.bs * 2 #This needs to be added\n",
    "        self.use_amp = True #need to add this to cfg\n",
    "        self.scheduler = 'GradualWarmupSchedulerV2'\n",
    "        self.warmup_factor = 10 #Need to add this \n",
    "        self.smp_lr = 1e-4 / self.warmup_factor #Need to add this\n",
    "        self.max_grad_norm = 1000 #To be added\n",
    "        self.num_workers = 4 #needs to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bda597",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG()\n",
    "cfg.__dict__\n",
    "cfg_df = pd.DataFrame([cfg.__dict__])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7084cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class CFG:\n",
    "\n",
    "#     # ============== pred target =============\n",
    "#     #target_size = 1 ##This can probably be removed, this wont change\n",
    "\n",
    "#     #============== file names =============\n",
    "        \n",
    "\n",
    "#     # ============== model cfg =============\n",
    "#     #model_name = 'Unet' #This can probably also be fixed \n",
    "    \n",
    "#     checkpoint = 'tu-eca_nfnet_l1' #called checkpoint\n",
    "#     frag_min = 31 \n",
    "#     frag_len = 4 \n",
    "    \n",
    "#     # ============== training cfg =============\n",
    "#     img_size = 224\n",
    "#     tile_size = 224 #needs to be added\n",
    "#     stride = tile_size // 2\n",
    "\n",
    "#     bs = 16 # 32 #change to bs\n",
    "#     valid_batch_size = bs * 2 #This needs to be added\n",
    "#     use_amp = True #need to add this to cfg\n",
    "\n",
    "#     scheduler = 'GradualWarmupSchedulerV2' #Need to add this \n",
    "#     n_epochs = 1 \n",
    "\n",
    "#     # adamW warmupあり\n",
    "#     warmup_factor = 10 #Need to add this \n",
    "#     smp_lr = 1e-4 / warmup_factor #Need to add this\n",
    "\n",
    "#     # ============== fold =============\n",
    "#     frag_sel = ['1', '2', '3'] #Just to test, would need to add two back in\n",
    "#     val_fold = 0 # dpnt think this is needed\n",
    "\n",
    "\n",
    "#     # ============== fixed =============\n",
    "#     max_grad_norm = 1000 #To be added\n",
    "#     num_workers = 4 #needs to be added\n",
    "#     random_seed = 42\n",
    "    \n",
    "#     # ============== augmentation =============\n",
    "\n",
    "#     augment = 'basic'\n",
    "    \n",
    "    \n",
    "# #     env = detect_env()\n",
    "\n",
    "# #     exp_name = 'vesuvius_2d_slide_exp002'\n",
    "# #     comp_name = 'vesuvius'\n",
    "# #     if env == 'kaggle':\n",
    "    \n",
    "# #         # comp_dir_path = './'\n",
    "# #         comp_dir_path = Path('/kaggle/input/')\n",
    "# #         comp_folder_name = 'vesuvius-challenge-ink-detection'\n",
    "# #         # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n",
    "# #         comp_dataset_path = comp_dir_path / comp_folder_name\n",
    "\n",
    "# #         outputs_path = Path(f'/kaggle/working/outputs/{comp_name}/{exp_name}/')\n",
    "\n",
    "# #         submission_dir = outputs_path /'submissions/'\n",
    "# #         submission_path = submission_dir / f'submission_{exp_name}.csv'\n",
    "\n",
    "# #         model_dir = outputs_path / f'{comp_name}-models/'\n",
    "\n",
    "# #         figures_dir = outputs_path / 'figures/'\n",
    "\n",
    "# #         log_dir = outputs_path / 'logs/'\n",
    "        \n",
    "    \n",
    "# #     else: ##Assume local and data is in folder called data, otherwise everything is the same\n",
    "        \n",
    "# #         path_main, path_data = get_paths(env)\n",
    "# #         #path_main = path_working = Path(\"..\")\n",
    "# #         comp_dataset_path = path_main / \"data\"\n",
    "# #         outputs_path = path_main\n",
    "        \n",
    "# #         submission_dir = outputs_path / 'submissions'\n",
    "# #         submission_path = submission_dir / f'submission_{exp_name}.csv'\n",
    "\n",
    "# #         model_dir = outputs_path / f'{comp_name}-models/'\n",
    "\n",
    "# #         figures_dir = outputs_path / 'figures'\n",
    "\n",
    "# #         log_dir = outputs_path / 'logs'\n",
    "        \n",
    "# #     cfg_list = [\n",
    "# #     'checkpoint',\n",
    "# #     'in_chans',\n",
    "# #     'size',\n",
    "# #     'tile_size',\n",
    "# #     'stride',\n",
    "# #     'train_batch_size',\n",
    "# #     'valid_batch_size',\n",
    "# #     'use_amp',\n",
    "# #     'scheduler',\n",
    "# #     'epochs',\n",
    "# #     'warmup_factor',\n",
    "# #     'lr',\n",
    "# #     'valid_set',\n",
    "# #     'valid_id',\n",
    "# #     'metric_direction',\n",
    "# #     'pretrained',\n",
    "# #     'inf_weight',\n",
    "# #     'min_lr',\n",
    "# #     'weight_decay',\n",
    "# #     'max_grad_norm',\n",
    "# #     'print_freq',\n",
    "# #     'num_workers',\n",
    "# #     'seed'\n",
    "# #     ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#from the util package, but putting here to make it easier\n",
    "def get_train_aug_resize(img_size, in_chans): return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "def get_valid_aug_resize(img_size, in_chans): return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "], p=1.)\n",
    "\n",
    "\n",
    "def get_train_aug_brightness(img_size, in_chans): return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.RandomBrightnessContrast(p = 0.5),\n",
    "    albumentations.HueSaturationValue(p = 0.5),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "def get_train_aug_bright_dropout_geom_blur(img_size, in_chans): return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.RandomBrightnessContrast(p = 0.5),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.Blur(p = 0.5),\n",
    "    albumentations.CoarseDropout(p = 0.5),\n",
    "    albumentations.ShiftScaleRotate(p=0.5, rotate_limit=15),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "def get_train_aug_public_baseline(img_size, in_chans):  return albumentations.Compose([\n",
    "    albumentations.Resize(img_size, img_size),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.RandomBrightnessContrast(p=0.75),\n",
    "    albumentations.ShiftScaleRotate(p=0.75),\n",
    "    albumentations.OneOf([\n",
    "            albumentations.GaussNoise(var_limit=[10, 50]),\n",
    "            albumentations.GaussianBlur(),\n",
    "            albumentations.MotionBlur(),\n",
    "            ], p=0.4),\n",
    "    albumentations.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "    albumentations.CoarseDropout(max_holes=1, max_width=int(img_size * 0.3), max_height=int(img_size * 0.3), \n",
    "                    mask_fill_value=0, p=0.5),\n",
    "    albumentations.Normalize(mean = [0] * in_chans, std = [1] * in_chans),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "def get_train_transforms(cfg):\n",
    "    \n",
    "    # augmentations\n",
    "    #---------------------\n",
    "    if cfg.augment == \"basic\":\n",
    "        get_train_aug = get_train_aug_resize\n",
    "    elif cfg.augment == \"brightness\":\n",
    "        get_train_aug = get_train_aug_brightness\n",
    "#     elif cfg.augment == \"geometry\":\n",
    "#         get_train_aug = get_train_aug_geometry\n",
    "    elif cfg.augment == \"baseline\":\n",
    "        get_train_aug = get_train_aug_public_baseline\n",
    "    elif cfg.augment == \"bright_dropout_geom_blur\":\n",
    "        get_train_aug = get_train_aug_bright_dropout_geom_blur\n",
    "    else:\n",
    "        get_train_aug = get_train_aug_resize\n",
    "        \n",
    "        \n",
    "    return get_train_aug(cfg.img_size, cfg.frag_len)\n",
    "\n",
    "def get_valid_transforms(cfg):\n",
    "    get_valid_aug = get_valid_aug_resize\n",
    "    return get_valid_aug(cfg.img_size, cfg.frag_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe64d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "def init_logger(log_file):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "def set_seed(seed=None, cudnn_deterministic=True):\n",
    "    if seed is None:\n",
    "        seed = 42\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = cudnn_deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def make_dirs(cfg):\n",
    "    \n",
    "    for dir in [CFG.model_dir, CFG.figures_dir, CFG.submission_dir, CFG.log_dir]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "        \n",
    "def cfg_init(cfg, mode='train'):\n",
    "    set_seed(cfg.random_seed)\n",
    "    # set_env_name()\n",
    "    # set_dataset_path(cfg)\n",
    "\n",
    "#     if mode == 'train':\n",
    "#         make_dirs(cfg)\n",
    "        \n",
    "# def make_cfg_dict(): #converts cfg into a dict for pandas \n",
    "#     dict_test = CFG.__dict__.copy() #not the most elegant way to do this, to be changed\n",
    "#     dict_test['valid_set'] = str(dict_test['valid_set'])\n",
    "#     dict_test['train_aug_list'] = str(dict_test['train_aug_list'])\n",
    "#     dict_test['valid_aug_list'] = str(dict_test['valid_aug_list'])\n",
    "#     samp_dict = {}\n",
    "#     for x in CFG.cfg_list:\n",
    "#         samp_dict[x] = dict_test[x]\n",
    "        \n",
    "#     return samp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfg_init(CFG)\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Logger = init_logger(log_file=CFG.log_path)\n",
    "\n",
    "#Logger.info('\\n\\n-------- exp_info -----------------')\n",
    "# Logger.info(datetime.datetime.now().strftime('%Y年%m月%d日 %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f8f427",
   "metadata": {},
   "source": [
    "# Reading Image + Mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def read_image_mask(CFG, fragment_id, path_train): ##Reads an individual mask framgment\n",
    "\n",
    "    images = []\n",
    "\n",
    "    # idxs = range(65)\n",
    "\n",
    "    \n",
    "#Old logic that started at a mid point\n",
    "#     mid = 65 // 2\n",
    "#     start = mid - CFG.frag_len // 2\n",
    "#     end = mid + CFG.frag_len // 2\n",
    "\n",
    "    start = CFG.frag_min\n",
    "    end = CFG.frag_min + CFG.frag_len\n",
    "    idxs = range(start, end)\n",
    "\n",
    "    for i in tqdm(idxs):\n",
    "\n",
    "        image_path = str(path_train / f\"{fragment_id}/surface_volume/{i:02}.tif\")\n",
    "        image = cv2.imread(image_path, 0)\n",
    "\n",
    "        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
    "        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n",
    "\n",
    "        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "        images.append(image)\n",
    "    images = np.stack(images, axis=2)\n",
    "\n",
    "    mask_path = str(path_train / f\"{fragment_id}/inklabels.png\")\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "    mask = mask.astype('float32')\n",
    "    mask /= 255.0\n",
    "    \n",
    "    label_path = str(path_train / f\"{fragment_id}/mask.png\")\n",
    "    label = cv2.imread(label_path, 0)\n",
    "    label = np.pad(label, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "    label = label.astype('float32')\n",
    "    label /= 255.0\n",
    "    \n",
    "    return images, mask, label.astype('int8')\n",
    "\n",
    "import gc\n",
    "def read_all_fragments(CFG, path_train): #Gets training/val data \n",
    "    \n",
    "    full_images = []\n",
    "    full_masks = []\n",
    "    full_xyxys = []\n",
    "\n",
    "    for fragment_id in range(1, 4): \n",
    "        \n",
    "        images = []\n",
    "        masks = []\n",
    "        xyxys = []\n",
    "        \n",
    "        image, mask, label = read_image_mask(CFG, fragment_id, path_train)\n",
    "\n",
    "        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
    "        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n",
    "\n",
    "        for y1 in y1_list:\n",
    "            for x1 in x1_list:\n",
    "                y2 = y1 + CFG.tile_size\n",
    "                x2 = x1 + CFG.tile_size\n",
    "                # xyxys.append((x1, y1, x2, y2))\n",
    "                \n",
    "                if np.max(label[y1:y2, x1:x2]) == 1: #we have ink here\n",
    "                    images.append(image[y1:y2, x1:x2])\n",
    "                    masks.append(mask[y1:y2, x1:x2, None])\n",
    "                    xyxys.append([x1, y1, x2, y2])\n",
    "        \n",
    "        \n",
    "        full_images.append(images)\n",
    "        full_masks.append(masks)\n",
    "        full_xyxys.append(xyxys)\n",
    "        \n",
    "        del image, mask, label\n",
    "        gc.collect()\n",
    "\n",
    "    return full_images, full_masks, full_xyxys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf4112",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_transforms(data, cfg): \n",
    "    if data == 'train':\n",
    "        aug = get_train_transforms(cfg)\n",
    "    elif data == 'valid':\n",
    "        aug = get_valid_transforms(cfg)\n",
    "\n",
    "    # print(aug)\n",
    "    return aug\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, cfg, labels=None, transform=None):\n",
    "        self.images = images\n",
    "        self.cfg = cfg\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.df)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(image=image, mask=label)\n",
    "            image = data['image']\n",
    "            label = data['mask']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfe8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "  \n",
    "def create_dataloaders_new(CFG, full_images, full_masks, full_xyxys, valid_id):\n",
    "    valid_id_int = int(valid_id) - 1\n",
    "    \n",
    "    valid_images = full_images[valid_id_int]\n",
    "    valid_masks = full_masks[valid_id_int]\n",
    "    valid_xyxys  = full_xyxys[valid_id_int]\n",
    "    \n",
    "    if valid_id_int == 0:\n",
    "        train_images = full_images[1] + full_images[2]\n",
    "        train_masks = full_masks[1] + full_masks[2]\n",
    "    elif valid_id_int == 1:\n",
    "        train_images = full_images[0] + full_images[2]\n",
    "        train_masks = full_masks[0] + full_masks[2] \n",
    "    elif valid_id_int == 2:\n",
    "        train_images = full_images[0] + full_images[1]\n",
    "        train_masks = full_masks[0] + full_masks[1]  \n",
    "    \n",
    "    #train_images, train_masks, valid_images, valid_masks, valid_xyxys = get_train_valid_dataset(valid_id)\n",
    "    #valid_xyxys = np.stack(valid_xyxys)\n",
    "    \n",
    "    train_dataset = CustomDataset(\n",
    "    train_images, CFG, labels=train_masks, transform=get_transforms(data='train', cfg=CFG))\n",
    "    valid_dataset = CustomDataset(\n",
    "        valid_images, CFG, labels=valid_masks, transform=get_transforms(data='valid', cfg=CFG))\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.bs,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n",
    "                              )\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.valid_batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    #print(len(train_loader))\n",
    "    #print(len(valid_loader))\n",
    "    return train_loader, valid_loader, valid_xyxys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2054ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def valid_mask_gt_func(fragment_id, path_train, CFG):\n",
    "    valid_mask_path = str(path_train / f\"{fragment_id}/inklabels.png\")\n",
    "    valid_mask_gt = cv2.imread(valid_mask_path, 0)\n",
    "    valid_mask_gt = valid_mask_gt / 255\n",
    "    pad0 = (CFG.tile_size - valid_mask_gt.shape[0] % CFG.tile_size)\n",
    "    pad1 = (CFG.tile_size - valid_mask_gt.shape[1] % CFG.tile_size)\n",
    "    valid_mask_gt = np.pad(valid_mask_gt, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "    return valid_mask_gt.astype('float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf689c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, weight=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.encoder = smp.Unet(\n",
    "            encoder_name=cfg.checkpoint, \n",
    "            encoder_weights=weight,\n",
    "            in_channels=cfg.frag_len,\n",
    "            classes=1, #hard coding for now \n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.encoder(image)\n",
    "        # output = output.squeeze(-1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def build_model(cfg, weight=\"imagenet\"):\n",
    "    print('model_name', \"Unet\") #used to be cfg.model_name\n",
    "    print('checkpoint', cfg.checkpoint)\n",
    "\n",
    "    model = CustomModel(cfg, weight)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6319bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def initalize_model(device, CFG):\n",
    "    model = build_model(CFG)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG.smp_lr)\n",
    "    scheduler = get_scheduler(CFG, optimizer)\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce262ac",
   "metadata": {},
   "source": [
    "# Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d710ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "\n",
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(\n",
    "            optimizer, multiplier, total_epoch, after_scheduler)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [\n",
    "                        base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, cfg.n_epochs, eta_min=1e-7)\n",
    "    scheduler = GradualWarmupSchedulerV2(\n",
    "        optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n",
    "\n",
    "    if cfg.scheduler == 'GradualWarmupSchedulerV2':\n",
    "        ret_scheduler = scheduler\n",
    "    elif cfg.scheduler == 'cosine':\n",
    "        ret_scheduler = scheduler_cosine\n",
    "    else:\n",
    "        ret_scheduler = scheduler\n",
    "    \n",
    "    return ret_scheduler\n",
    "\n",
    "def scheduler_step(scheduler, avg_val_loss, epoch):\n",
    "    scheduler.step(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c36d3",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77cf8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DiceLoss = smp.losses.DiceLoss(mode='binary')\n",
    "BCELoss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "\n",
    "alpha = 0.5\n",
    "beta = 1 - alpha\n",
    "TverskyLoss = smp.losses.TverskyLoss(\n",
    "    mode='binary', log_loss=False, alpha=alpha, beta=beta)\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n",
    "    return BCELoss(y_pred, y_true)\n",
    "    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * TverskyLoss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1456d",
   "metadata": {},
   "source": [
    "# Train / Val Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78458ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_fn(train_loader, model, criterion, optimizer, device, CFG):\n",
    "    model.train()\n",
    "\n",
    "    scaler = GradScaler(enabled=CFG.use_amp)\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with autocast(CFG.use_amp):\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt, CFG):\n",
    "    mask_pred = np.zeros(valid_mask_gt.shape)\n",
    "    mask_count = np.zeros(valid_mask_gt.shape)\n",
    "\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # make whole mask\n",
    "        y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n",
    "        start_idx = step*CFG.valid_batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        for i, (x1, y1, x2, y2) in enumerate(valid_xyxys[start_idx:end_idx]):\n",
    "            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n",
    "            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n",
    "\n",
    "    print(f'mask_count_min: {mask_count.min()}')\n",
    "    mask_pred /= mask_count\n",
    "    return losses.avg, mask_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d3769",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa852aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n",
    "    \"\"\"\n",
    "    y_true_count = targets.sum()\n",
    "    ctp = preds[targets==1].sum()\n",
    "    cfp = preds[targets==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "\n",
    "    c_precision = ctp / (ctp + cfp + smooth)\n",
    "    c_recall = ctp / (y_true_count + smooth)\n",
    "    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def calc_fbeta(mask, mask_pred):\n",
    "    mask = mask.astype(int).flatten()\n",
    "    mask_pred = mask_pred.flatten()\n",
    "\n",
    "    best_th = 0\n",
    "    best_dice = 0\n",
    "    dice = fbeta_numpy(mask, (mask_pred >= 0.5).astype(int), beta=0.5)\n",
    "    \n",
    "    best_dice = dice\n",
    "    best_th = 0.5 #assumed this is 0.5 vs iterating over different thresholds\n",
    "# Commented this out to save memory \n",
    "#     for th in np.array(range(10, 50+1, 5)) / 100:\n",
    "        \n",
    "#         # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n",
    "#         dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n",
    "#         print(f'th: {th}, fbeta: {dice}')\n",
    "\n",
    "#         if dice > best_dice:\n",
    "#             best_dice = dice\n",
    "#             best_th = th\n",
    "    \n",
    "#     Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n",
    "    return best_dice, best_th\n",
    "\n",
    "\n",
    "def calc_cv(mask_gt, mask_pred):\n",
    "    best_dice, best_th = calc_fbeta(mask_gt, mask_pred)\n",
    "\n",
    "    return best_dice, best_th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5300bb",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cpu_stats():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memory_use = py.memory_info()[0] / 2. ** 30\n",
    "    return 'memory GB:' + str(np.round(memory_use, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d827406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def train_one_fold(CFG, full_images, full_masks, full_xyxys, fold, device, path_train, path_test, path_models, path_logs, path_working): #Inputs are config file, underlying data, and fold num \n",
    "    \n",
    "    \n",
    "    best_score = -1\n",
    "    # timing\n",
    "    start_all = time.time()\n",
    "    \n",
    "    best_epoch_num = 0\n",
    "\n",
    "#     run_id = CFG.run_id\n",
    "#     grid_id = CFG.grid_id\n",
    "\n",
    "    #full_images, full_masks, full_xyxys = read_all_fragments() #reads and puts all fragments in list\n",
    "    #Note the above code ^^^^ doesnt need to be re-initalized every fold.\n",
    "    ###Maybe we create it in pre-proc and just pass it thru\n",
    "\n",
    "    train_loader, valid_loader, valid_xyxys = create_dataloaders_new(CFG, full_images ,full_masks ,full_xyxys, fold) \n",
    "    valid_mask_gt = valid_mask_gt_func(fold, path_train, CFG) #Get validation mask\n",
    "    model, optimizer, scheduler = initalize_model(device, CFG)\n",
    "    \n",
    "    epoc_count_l = []\n",
    "    train_loss_l = []\n",
    "    val_loss_l = []\n",
    "    val_dice_l = []\n",
    "    best_dice_score_l = []\n",
    "    best_epoch_l = []\n",
    "    epoch_time_l = []\n",
    "    fold_list_l = []\n",
    "    \n",
    "    for epoch in range(CFG.n_epochs):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # train\n",
    "            avg_loss = train_fn(train_loader, model, criterion, optimizer, device, CFG)\n",
    "\n",
    "            print(f'post training {fold}: {cpu_stats()}')\n",
    "            # eval\n",
    "            avg_val_loss, mask_pred = valid_fn(\n",
    "                valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt, CFG)\n",
    "\n",
    "            scheduler_step(scheduler, avg_val_loss, epoch)\n",
    "\n",
    "            print(f'model end training cv: {cpu_stats()}')\n",
    "            best_dice, best_th = calc_cv(valid_mask_gt, mask_pred)\n",
    "\n",
    "            print(f'finished calc cv: {cpu_stats()}')\n",
    "            # score = avg_val_loss\n",
    "            score = best_dice\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "#             Logger.info(\n",
    "#                 f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "#             # Logger.info(f'Epoch {epoch+1} - avgScore: {avg_score:.4f}')\n",
    "#             Logger.info(\n",
    "#                 f'Epoch {epoch+1} - avgScore: {score:.4f}')\n",
    "\n",
    "\n",
    "            update_best = score > best_score\n",
    "\n",
    "            if update_best:\n",
    "                best_loss = avg_val_loss\n",
    "                best_score = score\n",
    "                best_epoch_num = epoch\n",
    "#                 Logger.info(\n",
    "#                     f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "#                 Logger.info(\n",
    "#                     f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "\n",
    "                print(f'saving model: {cpu_stats()}')\n",
    "                torch.save({'model': model.state_dict(),\n",
    "                            'preds': mask_pred},\n",
    "                            path_models / f'Unet_fold{fold}_best.pth')\n",
    "                print(f'model saved: {cpu_stats()}')\n",
    "\n",
    "            epoc_count_l.append(epoch)\n",
    "            train_loss_l.append(avg_loss)\n",
    "            val_loss_l.append(avg_val_loss)\n",
    "            val_dice_l.append(best_dice)\n",
    "            best_dice_score_l.append(best_score)\n",
    "            best_epoch_l.append(best_epoch_num)\n",
    "            epoch_time_l.append(elapsed)\n",
    "            fold_list_l.append(fold)\n",
    "            \n",
    "            \n",
    "    base_df = pd.DataFrame( #Create DF based on training data \n",
    "        list(zip(epoc_count_l ,train_loss_l ,val_loss_l ,val_dice_l ,best_dice_score_l ,best_epoch_l ,epoch_time_l, fold_list_l )),\n",
    "                      \n",
    "        columns = ['epoc_count','train_loss','val_loss','val_dice','best_dice','best_epoch','epoch_time', 'fold_number'])\n",
    "                     \n",
    "    cfg_df = pd.DataFrame([CFG.__dict__])\n",
    "\n",
    "    log_df = pd.concat([base_df, cfg_df], axis = 1)\n",
    "    log_df = log_df.fillna(method=\"ffill\")\n",
    "    \n",
    "    return log_df\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34cef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_grid():\n",
    "    cfg = CFG()\n",
    "    cfg_init(cfg)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    path_train, path_test, path_models, path_logs, path_working = get_paths(detect_env())  #Gets our paths\n",
    "    \n",
    "    full_images, full_masks, full_xyxys = read_all_fragments(cfg, path_train) #Preprocessing, read in the fragments\n",
    "    \n",
    "    log_df_all = None\n",
    "    for fold in cfg.frag_sel: #valid_set is for the framgments we want to use in validation\n",
    "        log_df = train_one_fold(cfg, full_images, full_masks, full_xyxys, fold, device,\n",
    "                               path_train, path_test, path_models, path_logs, path_working) #Does one round of training\n",
    "        \n",
    "        if log_df_all is None:\n",
    "            log_df_all = log_df.copy()\n",
    "        else:\n",
    "            log_df_all = pd.concat([log_df_all, log_df])\n",
    "        \n",
    "    return log_df_all\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce740df",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "#nbdev.nbdev_test()\n",
    "nbdev.nbdev_export()\n",
    "#nbdev.nbdev_prepare()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
